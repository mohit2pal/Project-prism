{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Downloading data from Kaggle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import os\n",
    "import kaggle\n",
    "\n",
    "# Setting Kaggle API credentials\n",
    "os.environ[\"KAGGLE_USERNAME\"] = \"sryytuuy\"\n",
    "os.environ[\"KAGGLE_KEY\"] = \"cb97a52ed6a41de27e450cd527611d23\"\n",
    "\n",
    "# Authenticating Kaggle API\n",
    "kaggle.api.authenticate()\n",
    "\n",
    "# Downloading dataset from Kaggle\n",
    "kaggle.api.dataset_download_files('syedsaqlainhussain/cross-site-scripting-xss-dataset-for-deep-learning', path='data', unzip=True, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #999999; font-size: 12px\">This Python code downloads a dataset from Kaggle using the Kaggle API. It sets the necessary credentials, authenticates the API, and downloads the dataset to a specified location. The code imports the \"os\" and \"kaggle\" libraries, sets the Kaggle API credentials, authenticates the Kaggle API, and downloads the dataset from the \"syedsaqlainhussain/cross-site-scripting-xss-dataset-for-deep-learning\" Kaggle dataset to the \"data\" folder.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing data and spliting into train and test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the XSS dataset from the CSV file\n",
    "df = pd.read_csv(\"./data/XSS_dataset.csv\", header=0, index_col=0)\n",
    "\n",
    "# Split the dataset into input features (X) and labels (Y)\n",
    "X = df[\"Sentence\"].values\n",
    "Y = df[\"Label\"].values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #999999; font-size: 12px\">This Python code loads an XSS dataset from a CSV file, splits it into input features and labels, and then splits it into training and testing sets using the `train_test_split()` function from the `sklearn.model_selection` library. The code imports the necessary libraries, including pandas and sklearn.model_selection. The XSS dataset is loaded from a CSV file using the `pd.read_csv()` function, and the input features and labels are selected from the DataFrame. The `train_test_split()` function is used to split the dataset into training and testing sets, with the `test_size` argument set to 0.2 to use 20% of the dataset for testing and the `random_state` argument set to 42 to ensure that the same random split is generated every time the code is run.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
